{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Haplotype sequences from bam file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allele_functions.cigar_funcs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get variables needed (use Argparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hapFileName = '/Users/hughcross/Analysis/repos/meta_tools/example_haplotypes.txt'\n",
    "posFileName = '/Users/hughcross/Analysis/repos/meta_tools/example_position_list.txt'\n",
    "bamFileName = '/Users/hughcross/Analysis/Paua/sort_allBucks.bam'\n",
    "refName = 'CCB11_Haplotype1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort_allBucks\n"
     ]
    }
   ],
   "source": [
    "bamNameNoPath = bamFileName.split('/')[-1]\n",
    "sampleName = bamNameNoPath.split('.')[0]\n",
    "print(sampleName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort_allBucks.log\n"
     ]
    }
   ],
   "source": [
    "logFileName = sampleName+'.log'\n",
    "print(logFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dict of haplotypes and list of positions from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hapFile = open(hapFileName, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "{'CAGGAGT': '1', 'TAGGGGT': '2', 'CAGGAAT': '3', 'CAAAAGT': '4', 'TGGGAGT': '5', 'CAAGAGT': '6', 'TAGGGGC': '7'}\n",
      "['1', '2', '3', '4', '5', '6', '7']\n"
     ]
    }
   ],
   "source": [
    "hapDict = {}\n",
    "hList = []\n",
    "for line in hapFile:\n",
    "    line = line.strip('\\n')\n",
    "    parts = line.split('\\t')\n",
    "    hapDict[parts[1]]=parts[0]\n",
    "    hList.append(parts[0])\n",
    "hapFile.close()\n",
    "print(len(hapDict))\n",
    "print(hapDict)\n",
    "print(hList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "posFile = open(posFileName, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 25, 139, 160, 220, 304, 343]\n",
      "(10, 25, 139, 160, 220, 304, 343)\n"
     ]
    }
   ],
   "source": [
    "posList = []\n",
    "for line in posFile:\n",
    "    line = line.strip('\\n')\n",
    "    posList.append(int(line))\n",
    "posFile.close()\n",
    "positions = tuple(posList)\n",
    "print(posList)\n",
    "print(positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use pysam to parse the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamfileE = pysam.AlignmentFile(bamFileName, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hap1 = bamfileE.fetch(refName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hughcross/anaconda/envs/py3/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157698\n",
      "157698\n"
     ]
    }
   ],
   "source": [
    "# more complicated\n",
    "cigD = {}\n",
    "seqD = {}\n",
    "for c in hap1:\n",
    "    qy = c.query_name\n",
    "    cig = c.cigarstring\n",
    "    cigRef = cigar_ref(cig)\n",
    "    # make seqdict with quality\n",
    "    seq = c.query_sequence\n",
    "    qual = c.query_qualities\n",
    "    seqD.setdefault(qy, {})['seq']=seq\n",
    "    seqD.setdefault(qy, {})['qual']=qual\n",
    "    # get haplotype for each\n",
    "    hapStr = ''\n",
    "    for p in positions:\n",
    "        posi = posi_finder(cigRef, p)\n",
    "        if len(seq) > posi:\n",
    "            base = seq[posi]\n",
    "            hapStr = hapStr + base\n",
    "    cigD[qy]=hapStr\n",
    "print(len(cigD))\n",
    "print(len(seqD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13531\n"
     ]
    }
   ],
   "source": [
    "hapLists = {}\n",
    "notFound = []\n",
    "for k,v in cigD.items():\n",
    "    if v in hapDict:\n",
    "        htype = hapDict[v]\n",
    "        hapLists.setdefault(htype, []).append(k)\n",
    "    else:\n",
    "        notFound.append(k)\n",
    "        \n",
    "print(len(notFound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to sequence files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fasta file\n",
    "for hap in hList:\n",
    "    newFileName = sampleName+'_haplotype'+hap+'.fasta'\n",
    "    output = open(newFileName, 'w')\n",
    "    readlist = hapLists[hap]\n",
    "    for read in readlist:\n",
    "        output.write('>'+read+'\\n'+seqD[read]['seq']+'\\n')\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fastq file\n",
    "for hap in hList:\n",
    "    newFileName = sampleName+'_haplotype'+hap+'.fasta'\n",
    "    output = open(newFileName, 'w')\n",
    "    readlist = hapLists[hap]\n",
    "    for read in readlist:\n",
    "        output.write('@'+read+'\\n'+seqD[read]['seq']+'\\n+\\n'+seqD[read]['qual']+'\\n')\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output logfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logout = open(logFileName,'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logout.write('Haplotype\\tNumber of reads\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in hList:\n",
    "    numReads = str(len(hapLists[h]))\n",
    "    logout.write(h+'\\t'+numReads+'\\n')\n",
    "logout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
